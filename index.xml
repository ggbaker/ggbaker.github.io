<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Gary Baker</title>
    <link>https://www.garygbaker.com/</link>
      <atom:link href="https://www.garygbaker.com/index.xml" rel="self" type="application/rss+xml" />
    <description>Gary Baker</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Â© 2020 Gary Baker</copyright><lastBuildDate>Mon, 26 Oct 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://www.garygbaker.com/img/icon-32.png</url>
      <title>Gary Baker</title>
      <link>https://www.garygbaker.com/</link>
    </image>
    
    <item>
      <title>Consumer theory for cheap information</title>
      <link>https://www.garygbaker.com/publication/info-consumer-theory/</link>
      <pubDate>Mon, 26 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://www.garygbaker.com/publication/info-consumer-theory/</guid>
      <description>
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/iKf5Wh76iMA&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>Bayesian foundations for an asymptotically optimal experiment design (with Samuel Engle)</title>
      <link>https://www.garygbaker.com/publication/experiment-design/</link>
      <pubDate>Sun, 25 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://www.garygbaker.com/publication/experiment-design/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Remote teaching and seminars with OBS</title>
      <link>https://www.garygbaker.com/post/presentations/</link>
      <pubDate>Tue, 20 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://www.garygbaker.com/post/presentations/</guid>
      <description>












&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;featured.png&#34; data-caption=&#34;A scene from my department job talk&#34;&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    A scene from my department job talk
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h1 id=&#34;background&#34;&gt;Background&lt;/h1&gt;
&lt;p&gt;Like most grad students entering the job market this year, I&amp;rsquo;ve had to
wrestle with the transition to giving talks remotely. Personally, I have
some trouble focusing on virtual seminars since the format tends to be
fairly static: mostly still slides with perhaps a camera window to the
side. To avoid this, I&amp;rsquo;ve spent a fair amount of time (&lt;em&gt;read&lt;/em&gt;:
procrastinating) trying to put together a setup that allows me to move
around and interact with my materials a bit more. Below, I outline an
approach that&amp;rsquo;s worked reasonably well for me.&lt;/p&gt;
&lt;p&gt;Since I&amp;rsquo;m not teaching this semester, I&amp;rsquo;ve mostly focused on how to
adapt an academic seminar to a remote setting, but I would use a
variation of this for remote teaching given the opportunity.&lt;/p&gt;
&lt;p&gt;I set out to replicate three particular aspects of in-person
seminars/teaching:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The ability to easily handwrite equations/graphs on a blackboard,&lt;/li&gt;
&lt;li&gt;The ability to draw attention to certain parts of a slide or
blackboard, whether by laser pointer or physically pointing, and&lt;/li&gt;
&lt;li&gt;The ability to move and gesture while speaking.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For all of this, I&amp;rsquo;m indebted to the work of others who took time
to experiment with different methods for remote teaching/seminars and
create guides. In particular,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Luke Stein&amp;rsquo;s YouTube series: &lt;a href=&#34;https://www.youtube.com/watch?v=upTyHsxdlYs&amp;amp;list=PLEPYFCNANvR_ZFZVPp-y_-eo5-AlOK_0Z&#34;&gt;OBS for teaching tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;David J. Malan&amp;rsquo;s post: &lt;a href=&#34;https://medium.com/@cs50/teaching-from-home-via-zoom-c3b336446fbc&#34;&gt;Teaching from Home via
Zoom&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;A variety of twitter posts by Emily Nix, for example,
&lt;a href=&#34;https://twitter.com/EmilyNix100/status/1297261177060302849?s=20&#34;&gt;here&lt;/a&gt;
and &lt;a href=&#34;https://twitter.com/EmilyNix100/status/1294068665655025664?s=20&#34;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;hardware&#34;&gt;Hardware&lt;/h1&gt;
&lt;h2 id=&#34;needed-harware&#34;&gt;Needed harware:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;A computer (obviously): a relatively recent Mac would work best, but
isn&amp;rsquo;t required (My main desktop runs Linux)&lt;/li&gt;
&lt;li&gt;A good camera&lt;/li&gt;
&lt;li&gt;A tablet with stylus (iPad with Apple Pencil)&lt;/li&gt;
&lt;li&gt;A green screen and some way to hold it up&lt;/li&gt;
&lt;li&gt;A second monitor is a big plus&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I can&amp;rsquo;t overstate the importance of a good camera. If you
have a reasonably modern digital camera, there&amp;rsquo;s a good chance it can
send a video feed over usb to a computer. I use a Nikon D5500 that I
normally use for bird photography, but you almost certainly have a
pretty good webcam already available to you: a smart phone. Prior to
rigging up my Nikon, I simply used my smartphone on a cheap gooseneck
clamp using a free app called
&lt;a href=&#34;https://www.dev47apps.com/&#34;&gt;Droidcam&lt;/a&gt;. A wider angle lens is a big plus
here to give yourself more room to move around without having to stand
too far back.&lt;/p&gt;
&lt;p&gt;Even with a good camera, you need to be extremely well lit to get a good
image (and to get a good green screen effect). I use three lamps each
with some cheap 1500 lumen LED bulbs.&lt;/p&gt;
&lt;p&gt;For the microphone, so long as you don&amp;rsquo;t use your laptop&amp;rsquo;s built in-mic,
I don&amp;rsquo;t think the microphone is that important. The inline mic in most
earbuds works reasonably well, but it might be worth spending a little
bit on the mic. I use a Blue Yeti which works well enough (as a
condenser mic, it works reasonably well even sitting a bit back from
it), but if I had to do it again, I probably would have gotten a cheap
lav mic.&lt;/p&gt;
&lt;p&gt;Of course, to put yourself in the same scene with slides, there&amp;rsquo;s not
much substitute for a proper green screen. I got a cheap one on Amazon
for under $20, but be aware that the cheap screens come folded and need
steam-ironing to remove the creases. Ideally, you&amp;rsquo;ll have a wall behind
you to mount it, but otherwise you&amp;rsquo;ll need some kind of stand (which
will add some expense).&lt;/p&gt;
&lt;p&gt;Lastly, you&amp;rsquo;ll need some way to write easily. For me, that means an iPad
with the Apple Pencil. You will also need some way to get the video feed
from the tablet into your computer.&lt;/p&gt;
&lt;p&gt;Finally, it&amp;rsquo;s extremely useful (though not necessary) to have at least
one extra monitor so you can have the chat window and participants&amp;rsquo;
videos visible separately.&lt;/p&gt;
&lt;h2 id=&#34;room-setup&#34;&gt;Room setup&lt;/h2&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;messydesk.jpg&#34; data-caption=&#34;A very messy desk set up for presenting&#34;&gt;
&lt;img src=&#34;messydesk.jpg&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    A very messy desk set up for presenting
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;I sit on a bar stool about 1.5 meters back from my camera in the left
third of the camera&amp;rsquo;s field of view. This leaves most of the camera&amp;rsquo;s
field of view as empty green screen that I can fill with the slides and
gesture over. In the image below showing the OBS setup, the red box is
the extent of the area I can gesture in. My camera lens is fairly wide
(28mm full-frame equivalent, roughly an 80 degree field of view). If
you&amp;rsquo;re using a narrower camera angle&amp;mdash;most smart phones are probably
closer to 60 degrees&amp;mdash;you&amp;rsquo;d have to sit farther back from the camera to
get a similar effect. If you&amp;rsquo;re considering buying a webcam, look for
one with a wider field of view.&lt;/p&gt;
&lt;p&gt;Since I&amp;rsquo;m sitting so far back from my desk, I also use a small table for
my iPad, and I adjust my microphone to be as close as possible.&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;roomsetup.jpg&#34; data-caption=&#34;Where I sit&#34;&gt;
&lt;img src=&#34;roomsetup.jpg&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Where I sit
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h1 id=&#34;software&#34;&gt;Software&lt;/h1&gt;
&lt;h2 id=&#34;needed-software&#34;&gt;Needed software&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://obsproject.com/&#34;&gt;OBS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Virtual Cam Extension for OBS
(&lt;a href=&#34;https://obsproject.com/forum/resources/obs-virtualcam.949/&#34;&gt;Windows&lt;/a&gt;,
&lt;a href=&#34;https://github.com/johnboiles/obs-mac-virtualcam&#34;&gt;Mac&lt;/a&gt;,
&lt;a href=&#34;https://github.com/CatxFish/obs-v4l2sink&#34;&gt;Linux&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;PDF software of choice on for the tablet (I use &lt;a href=&#34;https://readdle.com/documents&#34;&gt;Readdle
Documents&lt;/a&gt; on the iPad)&lt;/li&gt;
&lt;li&gt;Some way to get the video feed from the tablet to the computer (see below)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;obs-setup&#34;&gt;OBS setup&lt;/h2&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;obs.png&#34; data-caption=&#34;OBS Scene arrangement&#34;&gt;
&lt;img src=&#34;obs.png&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    OBS Scene arrangement
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Since many others have given excellent tutorials on how to use OBS (see
Luke Stein&amp;rsquo;s tutorial linked above), I&amp;rsquo;ll skip the details of the setup
and jump straight to the scene arrangement.&lt;/p&gt;
&lt;p&gt;My primary scene in OBS has three sources:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Webcam input, with Chroma Key (green screen) filter applied, and with
the image reflected (so I can more easily see where I&amp;rsquo;m &amp;ldquo;pointing&amp;rdquo;)&lt;/li&gt;
&lt;li&gt;Flat color as a background (black worked best for me)&lt;/li&gt;
&lt;li&gt;Video input from my iPad (see below)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In order to make better use of the space in the OBS canvas, I also
adjusted the aspect ratio of my beamer slides to be a bit more square
(12x10 worked will for me). This can be accomplished using the
&lt;code&gt;beamerposter&lt;/code&gt; package:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;\usepackage[orientation=landscape,size=custom,width=12,height=10,scale=0.5,debug]{beamerposter}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;video-input-from-tablet&#34;&gt;Video input from tablet&lt;/h2&gt;
&lt;p&gt;The biggest challenge of all this was finding a way to mirror my iPad&amp;rsquo;s
display to my desktop so OBS could use it. If you have a relatively
recent Mac, this is easy since recent Macs and iPads by default support
a system called &lt;a href=&#34;https://support.apple.com/en-us/HT210380&#34;&gt;Sidecar&lt;/a&gt; that
allows you to use your iPad as a second screen (with touch support) for
your Mac.&lt;/p&gt;
&lt;p&gt;Since my main desktop isn&amp;rsquo;t a Mac, I settled on using Apple&amp;rsquo;s
&lt;a href=&#34;https://www.apple.com/airplay/&#34;&gt;Airplay&lt;/a&gt; protocol to wirelessly mirror
my iPad display to my desktop; however, this isn&amp;rsquo;t supported by default
(Airplay is meant to mirror to a device like an AppleTV). Fortunately,
with appropriate software, a regular computer can become an Airplay
receiver. On Linux, this can be accomplished with an open source tool
called &lt;a href=&#34;https://github.com/antimof/UxPlay&#34;&gt;UxPlay&lt;/a&gt;. I know similar
software exists for Windows, but all options I saw were paid software,
so I&amp;rsquo;m hesitant to recommend one in particular without trying them
first.&lt;/p&gt;
&lt;h1 id=&#34;zoom-setup&#34;&gt;Zoom setup&lt;/h1&gt;
&lt;p&gt;Finally, we just need to get everything into Zoom. There&amp;rsquo;s two ways to
do this, each with it&amp;rsquo;s own advantages.&lt;/p&gt;
&lt;h2 id=&#34;webcam&#34;&gt;Webcam&lt;/h2&gt;
&lt;p&gt;The most straightforward method is to simply use the OBS virtual cam
extension (link above). Within Zoom, I&amp;rsquo;d recommend specifically
&amp;ldquo;spotlighting&amp;rdquo; your camera so the view doesn&amp;rsquo;t switch to another
person&amp;rsquo;s camera when they speak.&lt;/p&gt;
&lt;p&gt;Besides simplicity, this method is pretty much sure to work even if
you&amp;rsquo;re not using Zoom (say, Skype or Blackboard Collaborate)&amp;mdash;so long
as whatever system you&amp;rsquo;re using supports a webcam.&lt;/p&gt;
&lt;p&gt;The main issue I had with this method is that Zoom&amp;rsquo;s compression can
make the slide text difficult to read at times unless the internet
connection for everyone is absolutely perfect.&lt;/p&gt;
&lt;p&gt;This method also has the advantage that it&amp;rsquo;s likely to work with other
software such as Skype or Blackboard Collaborate.&lt;/p&gt;
&lt;h2 id=&#34;screen-sharing&#34;&gt;Screen sharing&lt;/h2&gt;
&lt;p&gt;I eventually settled on using the Screen Share feature with the
&amp;ldquo;optimize for video&amp;rdquo; setting enabled.&lt;/p&gt;
&lt;p&gt;First, I create a window with the OBS canvas output
(right click on the OBS canvas -&amp;gt; Fullscreen projector). I then share
this window with Zoom. Once screen sharing, I then disable my webcam in
zoom to avoid duplicate images.&lt;/p&gt;
&lt;p&gt;This method &lt;em&gt;mostly&lt;/em&gt; fixes the blurry text issue. Unfortunately, the
video feed can lag the audio a bit which can be distracting for
the viewers. This lag is somewhat unpredictable; in one of my practice
talks it was apparently up to a second, and in my final department talk it
wasn&amp;rsquo;t much of an issue at all. Your mileage may vary.&lt;/p&gt;
&lt;p&gt;I haven&amp;rsquo;t tested this method with non-Zoom conference software, but I
wouldn&amp;rsquo;t expect it to work well there. It seems like most software uses
a compression optimized for relatively static scenes for screen sharing,
so movement would likely appear very choppy to viewers. It only works in
Zoom because of Zoom&amp;rsquo;s &amp;ldquo;optimize for video option&amp;rdquo; for screen sharing.&lt;/p&gt;
&lt;h1 id=&#34;the-final-result&#34;&gt;The final result&lt;/h1&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;examplescene.gif&#34; data-caption=&#34;The final result&#34;&gt;
&lt;img src=&#34;examplescene.gif&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    The final result
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Overall, the whole setup is a bit of a house of cards, but it mostly
replicated what I felt were the most important aspects of in-person
talks.&lt;/p&gt;
&lt;p&gt;Although I haven&amp;rsquo;t had a chance to use this for teaching yet, I expect
things would work similarly well, either using a note-taking app on the
iPad for a pure &amp;ldquo;chalk-and-talk&amp;rdquo; sort of lecture or using a hybrid
approach mixing slides with handwriting.&lt;/p&gt;
&lt;h1 id=&#34;update-some-extra-considerations&#34;&gt;Update: Some extra considerations&lt;/h1&gt;
&lt;p&gt;One thing I forgot to mention: before trying any of this in an actual
talk, it&amp;rsquo;s very important to test it out with other people. You can&amp;rsquo;t
see exactly how Zoom or whatever software you&amp;rsquo;re using compresses the
video, so it&amp;rsquo;s important to check with other people whether the material
you&amp;rsquo;re showing is legible to others.&lt;/p&gt;
&lt;p&gt;Also, as I mentioned a bit before, the exact way Zoom handles video can
be a bit unpredictable, so it&amp;rsquo;s good to be prepared with a backup option
in case things unexpectedly go wrong. In my case, I have a backup &amp;ldquo;Scene
Collection&amp;rdquo; in OBS that is a more traditional arrangement of the slides
with a smaller camera overlay in the corner, and in an emergency I can
switch to that in about a minute.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Additional research projects</title>
      <link>https://www.garygbaker.com/publication/in-progress/</link>
      <pubDate>Tue, 29 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://www.garygbaker.com/publication/in-progress/</guid>
      <description>&lt;p&gt;&lt;em&gt;Bayesian foundations for an asymptotically optimal experiment design,&lt;/em&gt;
with Sam Engle&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Optimal fast experimentation,&lt;/em&gt; with Lones Smith&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Bargaining with multiple buyers: evidence from eBay&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Consumer theory for cheap information - Simulations</title>
      <link>https://www.garygbaker.com/web-appendices/info-consumer-theory/</link>
      <pubDate>Tue, 29 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://www.garygbaker.com/web-appendices/info-consumer-theory/</guid>
      <description>&lt;p&gt;My job market paper considers the substitutability between different
information sources at large sample size&amp;mdash;that is, when information is
sufficiently cheap and/or budgets sufficiently large. This file
illustrates the main results using Python.&lt;/p&gt;
&lt;p&gt;If you&amp;rsquo;d like to experiment yourself, the original Jupyter notebook can
be downloaded &lt;a href=&#34;files/info-consumer-theory.ipynb&#34;&gt;here&lt;/a&gt; (Right click -&amp;gt; &amp;ldquo;Save
Link As&amp;rdquo;).&lt;/p&gt;
&lt;h1 id=&#34;code-setup&#34;&gt;Code setup&lt;/h1&gt;
&lt;p&gt;First, we need to import a number of standard Python packages:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np                   &lt;span style=&#34;color:#75715e&#34;&gt;# Basic array stuff&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; scipy.optimize &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; optim       &lt;span style=&#34;color:#75715e&#34;&gt;# For finding function mins&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; scipy.stats &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; multinomial  &lt;span style=&#34;color:#75715e&#34;&gt;# Multinomial probability computation&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt      &lt;span style=&#34;color:#75715e&#34;&gt;# Plotting&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tabulate &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tabulate        &lt;span style=&#34;color:#75715e&#34;&gt;# For nicer printing of some data&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;model&#34;&gt;Model&lt;/h1&gt;
&lt;p&gt;A decision maker must take one of finitely many actions $a\in A$ facing
an uncertain state of the world, $\theta$, that is one of finitely many
possible states. She has a state-dependent payoff function,
$u(a,\theta)$ and chooses her action to maximize expected payoff. Her
prior is given by $p\in\Delta\Theta$.&lt;/p&gt;
&lt;p&gt;Prior to acting, she may purchase information about the state and update
her prior based on that information. As standard, define an information
as a &lt;em&gt;Blackwell experiment&lt;/em&gt;, that is, a collection of state-dependent
distributions, $F(r\ |\ \theta)$ over some realization space, R:&lt;/p&gt;
&lt;p&gt;$$
\mathcal{E} \equiv
\{R, \langle F(\cdot\ |\ \theta)\rangle_{\theta\in\Theta}\}
$$&lt;/p&gt;
&lt;p&gt;(In a fully formal treatment, the definition would also include a
Ï-algebra. For the purposes of this paper, we can ignore such
measure-theoretic complications).&lt;/p&gt;
&lt;p&gt;After observing a realization from an information source, the decision
maker can update with Bayes rule:&lt;/p&gt;
&lt;p&gt;$$
p_\theta&amp;rsquo;(r) = \frac{p_\theta f(r\ | \ \theta)}{\sum_{\theta&amp;rsquo;\in\Theta}p_{\theta&amp;rsquo;}f(r\ |\ \theta&amp;rsquo;)}
$$&lt;/p&gt;
&lt;p&gt;To avoid trivialities, assume that no realization perfectly rules in or
out any subset of the states, that is, if realization has positive
probability (density) under one state, it must have positive probability
under all states. (In technical terms, assume the $F(\cdot\ |\ \theta)$
are all mutually absolutely continuous so the Radon-Nikodym derivatives,
$dF(\cdot\ |\ \theta&amp;rsquo;)/dF(\cdot\ |\ \theta)$ all exist.) For notational
simplicity in this illustration, I&amp;rsquo;ll assume each state-dependent
distribution has finitely many possible realizations and thus pmf given
by, $f$.&lt;/p&gt;
&lt;p&gt;We can the define an &lt;em&gt;amount&lt;/em&gt; of information by a number of
conditionally independent samples from such a source.&lt;/p&gt;
&lt;p&gt;For illustration, consider a two-state world, $\theta\in\{H,L\}$. An
information source might be a coin that is fairly waited in the $L$
state, and biased 70% to heads in the $H$ state. Then samples from this
source would simply be the number of coin flips. In an experimental
setting, samples would be literal samples under some experimental
design.&lt;/p&gt;
&lt;p&gt;The DM has a collection of information sources $\mathcal{E}_i,\ldots,
\mathcal{E}_I$ from each of which she can purchase an arbitrary number
of samples, $\mathbf{n}=[n_i]$, at some cost $[c_i]$ each.&lt;/p&gt;
&lt;p&gt;The goal of this paper is to characterize the substitutability of
different information sources under the normal Bayesian (ex ante)
information value&amp;mdash;that is, the expected payoff gain from acting after
observing a realization from information source $\mathcal{E}$:&lt;/p&gt;
&lt;p&gt;$$ V(\mathcal{E}) \equiv \sum_{r\in R} \max_a {\sum_\theta p&amp;rsquo;_\theta(r)
u(a,\theta)} f(r) - \max_a {\sum_\theta p_\theta u(a,\theta)} $$
where $f(r)\equiv \sum_\theta p_\theta f(r\ |\ \theta)$ is the
unconditional realization probability for the given source.&lt;/p&gt;
&lt;p&gt;Information value is typically a very poorly behaved function, so I
approach the problem with an asymptotic approach using large deviations
methods.&lt;/p&gt;
&lt;p&gt;Throughout this notebook, I&amp;rsquo;ll be working with a 3 state decision
problem.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;numstates &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;composite-information-sources-and-information-values&#34;&gt;Composite information sources and information values&lt;/h1&gt;
&lt;h2 id=&#34;defining-information-sources&#34;&gt;Defining information sources&lt;/h2&gt;
&lt;p&gt;In order to simulate information values, we need a way to define
Blackwell experiments in a way amenable to computation: Define an
information source as a $|\Theta|\times|R|$ matrix, so each row of the
matrix lists the probability of each realization in that state. I will
typically use Q to denote such a matrix.&lt;/p&gt;
&lt;p&gt;The following code will specify a pair of experiments that happens to
look nice, but if you&amp;rsquo;re running the code yourself, you can use the
upper lines to create a pair of random experiments.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;rand_source&lt;/span&gt;(numstates, numrealizations):
    &lt;span style=&#34;color:#75715e&#34;&gt;# generate a random array with the appropriate dimension&lt;/span&gt;
    Q &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rand(numstates, numrealizations)
    &lt;span style=&#34;color:#75715e&#34;&gt;# normalize so each row sums to 1&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; state &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(numstates):
        Q[state, :] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Q[state, :] &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum(Q[state, :])
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; Q


&lt;span style=&#34;color:#75715e&#34;&gt;#Q1 = rand_source(numstates, 2)&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#Q2 = rand_source(numstates, 3)&lt;/span&gt;
Qperfect &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;eye(numstates)   &lt;span style=&#34;color:#75715e&#34;&gt;# Perfect information source&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# The following two make nice plots&lt;/span&gt;
Q1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([[&lt;span style=&#34;color:#ae81ff&#34;&gt;0.42&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.58&lt;/span&gt;],
               [&lt;span style=&#34;color:#ae81ff&#34;&gt;0.63&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.37&lt;/span&gt;],
               [&lt;span style=&#34;color:#ae81ff&#34;&gt;0.03&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.97&lt;/span&gt;]])
Q2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([[&lt;span style=&#34;color:#ae81ff&#34;&gt;0.07&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.18&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.75&lt;/span&gt;],
               [&lt;span style=&#34;color:#ae81ff&#34;&gt;0.45&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.19&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.36&lt;/span&gt;],
               [&lt;span style=&#34;color:#ae81ff&#34;&gt;0.45&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.05&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.50&lt;/span&gt;]])

&lt;span style=&#34;color:#75715e&#34;&gt;# state labels. Will use for nice output tables&lt;/span&gt;
states &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; stateidx &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(Q1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]):
    states&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append([&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;State {i}&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(i&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;stateidx)])

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Conditional probability of each realization:&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# Output table and print&lt;/span&gt;
table1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(states, Q1, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
realizations1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Q1&amp;#34;&lt;/span&gt;]
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; realization &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(Q1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]):
    realizations1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;R1 =&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(realization))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(tabulate(table1, headers&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;realizations1)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)

table2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(states, Q2, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
realizations2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Q2&amp;#34;&lt;/span&gt;]
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; realization &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(Q2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]):
    realizations2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;R2 =&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(realization))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(tabulate(table2, headers&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;realizations2))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Conditional probability of each realization:

Q1         R1 = 0    R1 = 1
-------  --------  --------
State 0      0.42      0.58
State 1      0.63      0.37
State 2      0.03      0.97

Q2         R2 = 0    R2 = 1    R2 = 2
-------  --------  --------  --------
State 0      0.07      0.18      0.75
State 1      0.45      0.19      0.36
State 2      0.45      0.05      0.5
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we need to be able to quickly compute the matrix for composite
experiments. First, we need to be able to compute the matrix for $n$
i.i.d. samples from 1 experiment.&lt;/p&gt;
&lt;p&gt;Since the total number of realizations of each type is a sufficient
statistic for the entire vector of realizations, we can simplify things
by first computing all of the partitions of $n$ with $|R|$ components
(all possible realization sums), the use a multinomial distribution.&lt;/p&gt;
&lt;p&gt;The output matrix will be $|\Theta|\times$(number of ways to sum $|R|$
positive integers to add up to $n$)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Compute appropriate partitions (returns a generator)&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;partitions&lt;/span&gt;(n, numrealizations):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; numrealizations &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
            &lt;span style=&#34;color:#66d9ef&#34;&gt;yield&lt;/span&gt; (n,)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(n&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; result &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; partitions(n&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;i, numrealizations&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
            &lt;span style=&#34;color:#66d9ef&#34;&gt;yield&lt;/span&gt; (i,) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; result


&lt;span style=&#34;color:#75715e&#34;&gt;# Compute matrix for the n-sample source&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;n_samples&lt;/span&gt;(Q, n):
    numstates &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Q&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
    numrealizations &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Q&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:                   &lt;span style=&#34;color:#75715e&#34;&gt;# return trivial experiment if 0 samples&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones((numstates, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
    QnT &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []                     &lt;span style=&#34;color:#75715e&#34;&gt;# transpose of Qn&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; outcome &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; partitions(n, numrealizations):
        outcomeprobs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []        &lt;span style=&#34;color:#75715e&#34;&gt;# column of state-dep outcome probs&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; state_idx &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(numstates):
            &lt;span style=&#34;color:#75715e&#34;&gt;# create a multinomial with the given outcome probs&lt;/span&gt;
            multinom &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; multinomial(n, Q[state_idx, :])
            outcomeprobs&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(multinom&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pmf(outcome))
        QnT&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(outcomeprobs)
    Qn &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(QnT)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;T         &lt;span style=&#34;color:#75715e&#34;&gt;# convert to array and transpose&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; Qn

n &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;
realizations1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [str(n) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; samples of Q1&amp;#34;&lt;/span&gt;]
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; outcome &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; partitions(n, Q1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]):
    realizations1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(outcome)
table &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(states, n_samples(Q1, n), axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;conditional probabilities of each sample combination:&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(tabulate(table, headers&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;realizations1))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;conditional probabilities of each sample combination:

3 samples of Q1      (0, 3)    (1, 2)    (2, 1)    (3, 0)
-----------------  --------  --------  --------  --------
State 0            0.195112  0.423864  0.306936  0.074088
State 1            0.050653  0.258741  0.440559  0.250047
State 2            0.912673  0.084681  0.002619  2.7e-05
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Second, we need to be able to composite two &lt;em&gt;distinct&lt;/em&gt; information
sources. If info source $\mathcal{E}_1$ and $\mathcal{E}_2$ have $|R_1|$
and $|R_2|$ possible realizations respectively, then the composite
source consisting of 1 sample from each has $|R_1|\times|R_2|$
outcomes. We can get a matrix of all possible combination probabilities
by simply by listing out each element of the outer product of the rows
of each matrix:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;composite_source&lt;/span&gt;(Q1, Q2):
    numstates &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Q1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
    numrealizations &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Q1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; Q2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
    Qcomp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;empty((numstates, numrealizations))  &lt;span style=&#34;color:#75715e&#34;&gt;# initialize output&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; state &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(numstates):
        &lt;span style=&#34;color:#75715e&#34;&gt;# compute all possible combination probs with an outer product&lt;/span&gt;
        Qcomp[state, :] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; \
            np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;outer(Q1[state, :], Q2[state, :]),
                       (numrealizations))           &lt;span style=&#34;color:#75715e&#34;&gt;# reshape to vect.&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; Qcomp


Q12comp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; composite_source(Q1, Q2)
realizations12 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;1 from each&amp;#34;&lt;/span&gt;]
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; r1idx &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(Q1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; r2idx &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(Q2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]):
        realizations12&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;R1={i1}, R2={i2}&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(i1&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;r1idx, i2&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;r2idx))
table &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(states, Q12comp, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Conditional probabilties of each combination of realizations from Q1 and Q2:&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(tabulate(table, headers&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;realizations12))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Conditional probabilties of each combination of realizations from Q1 and Q2:

1 from each      R1=0, R2=0    R1=0, R2=1    R1=0, R2=2    R1=1, R2=0    R1=1, R2=1    R1=1, R2=2
-------------  ------------  ------------  ------------  ------------  ------------  ------------
State 0              0.0294        0.0756        0.315         0.0406        0.1044        0.435
State 1              0.2835        0.1197        0.2268        0.1665        0.0703        0.1332
State 2              0.0135        0.0015        0.015         0.4365        0.0485        0.485
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that we repeated composite a matrix with itself to get an
equivalent $n$ sample matrix, but this would produce a massive matrix
(size $|R|^n$). Most computers would hit memory limitations for any
$n$ bigger than 20 or so brute forcing it like that isn&amp;rsquo;t practical.&lt;/p&gt;
&lt;h2 id=&#34;value-of-information&#34;&gt;Value of information&lt;/h2&gt;
&lt;p&gt;In order to compute information value, we must now define a
state-dependent utility function and a prior belief. I&amp;rsquo;ll code the
utility function as a $|A|\times|\Theta|$ matrix of payoffs where
$U_{a\theta}=u(a,\theta)$. The prior can simply be coded as a vector of
belief probabilities.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# example payoff matrix (payoff 1 only if choose the correct state)&lt;/span&gt;
U &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;eye(numstates)
&lt;span style=&#34;color:#75715e&#34;&gt;# example prior vector (diffuse prior)&lt;/span&gt;
P &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones(numstates) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; numstates
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Information value is typically a fairly tricky thing to compute. In
order to maximize computational efficiency, I vectorize the problem
where possible. For a given information matrix, $Q$, and payoff matrix
$U$, we can write the value &lt;em&gt;with&lt;/em&gt; information as&lt;/p&gt;
&lt;p&gt;$$ W(Q) = \max_D{\text{tr}(QDU\pi)}$$&lt;/p&gt;
&lt;p&gt;where $\pi$ is a matrix who&amp;rsquo;s diagonal elements are the prior
probabilities and $D$ is a $|R|\times|A|$ matrix specifying the
probability of taking each action after each realization (this is a
linear program: $D$ generically is all zeros and ones since each
realization generically has a unique optimal response.&lt;/p&gt;
&lt;p&gt;(&lt;a href=&#34;https://cpb-us-w2.wpmucdn.com/campuspress.yale.edu/dist/3/352/files/2013/01/LeshnoSpector92.pdf&#34;&gt;Leshno,
1992&lt;/a&gt;
uses this formulation to provide an elementary proof of Blackwell&amp;rsquo;s
theorem for the finite-action/finite-state case.)&lt;/p&gt;
&lt;p&gt;The value &lt;em&gt;of&lt;/em&gt; information would then be $W(Q)$ minus the payoff from
acting with no information. Such a subtraction is a monotone
transformation, so it won&amp;rsquo;t affect the ordinal properties I&amp;rsquo;m interested
in.&lt;/p&gt;
&lt;p&gt;In order to evaluate how close a bundle is to perfect information, I
will sometimes use the ratio of the full-information gap (the difference
between the value of a perfect signal and $W(Q)$, relative to the
full-info value. This will be a percentage that approaches zero as the
amount of samples increases.&lt;/p&gt;
&lt;p&gt;None of these approximation would be particularly useful if they require
so many samples as to be indistinguishable from a perfect source
anyways. I will thus use this relative info-gap as an ad hoc measure how
useful the approximation is. That is, the relevant approximations are
useful if they are accurate, even when the relative info-gap is large.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;info_value&lt;/span&gt;(Q, U, P):
    numrealizations &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Q&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]

    Upi &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; U &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;@&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;diag(P)
    &lt;span style=&#34;color:#75715e&#34;&gt;# compute (actions x realizations) matrix of payoff of each action&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;# times unconditional prob of each realization&lt;/span&gt;
    Ua &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Upi &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;@&lt;/span&gt; Q
    &lt;span style=&#34;color:#75715e&#34;&gt;# choose best action for each message then sum across messages&lt;/span&gt;
    valuewithinfo &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sum(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;amax(Ua, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;))
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; valuewithinfo

&lt;span style=&#34;color:#75715e&#34;&gt;# relative info gap&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;relative_info_gap&lt;/span&gt;(Q, U, P):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; (info_value(Qperfect, U, P) &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; info_value(Q, U, P)) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; info_value(Qperfect, U, P)

&lt;span style=&#34;color:#75715e&#34;&gt;# value of info for the examples above&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(tabulate([[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Expected value of acting after observing Q1:&amp;#34;&lt;/span&gt;,
                 info_value(Q1, U, P)]]))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;--------------------------------------------  --------
Expected value of acting after observing Q1:  0.533333
--------------------------------------------  --------
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;chernoff-precision&#34;&gt;Chernoff precision&lt;/h1&gt;
&lt;p&gt;In the paper, I show that two information sources are exchangeable with
ratios of respective precision-like indices of each experiment. In order
to define this precision, we must first take a brief detour into large
deviations theory.&lt;/p&gt;
&lt;p&gt;I approach the problem of approximating information values by
approximating the probability of a &amp;ldquo;mistake&amp;rdquo; (taking a suboptimal action
in a given state). The normal form of Bayes&amp;rsquo;s rule is a bit messy, so
instead of working with probabilities, I work with log-likelihood
ratios, where Bayes rule becomes a sum:&lt;/p&gt;
&lt;p&gt;$$
\log\bigg(\frac{p_{\theta}&#39;(r)}{p_{\theta&amp;rsquo;}&#39;(r)}\bigg) =
\log\bigg(\frac{p_\theta}{p_{\theta&amp;rsquo;}}\bigg) +
\log\bigg(\frac{f(r\ |\ \theta)}{f(r\ |\ \theta)}\bigg)
$$&lt;/p&gt;
&lt;p&gt;And, of course, we have no shortage of asymptotic results for
approximating sums of many independent distributions.&lt;/p&gt;
&lt;p&gt;For a given pair of states, define the Chernoff index of an experiment,
$\mathcal{E}_1$, as the minimized value of the moment generating
function (MGF) of the distribution of log-likelihood ratios (LLR):&lt;/p&gt;
&lt;p&gt;$$
\rho_1 \equiv \min_t \sum_r f(r\ |\ \theta)^t f(r\ |\ \theta&amp;rsquo;)^{1-t}
$$
(Define $\tau_1$ as the minimizer)&lt;/p&gt;
&lt;p&gt;Note that the expected value of the distribution of the above mgf is the
negative Kullback-Leibler divergence, $-D(F(\cdot\ |\ \theta&amp;rsquo;)\ ||&lt;br&gt;
F(\cdot\ |\ \theta))$.&lt;/p&gt;
&lt;p&gt;Note that because the MGF of an independent sum is the product of MGFs, we
have that $n$ samples from $\mathcal{E}_1$ will have Chernoff index
$\rho_1^n$.&lt;/p&gt;
&lt;p&gt;Furthermore, because the minimum of a sum will be bigger than the sum of
minima, we have that the Chernoff index of a composite is more than the
sum of its parts:&lt;/p&gt;
&lt;p&gt;$$
\rho_{12} \geq \rho_1\rho_2
$$&lt;/p&gt;
&lt;p&gt;Now, we can define the Chernoff &lt;em&gt;precision&lt;/em&gt; for a given state pair of a
test by $\beta \equiv -\log(\rho)$. I call this a precision because, for
Gaussian tests, it is, up to a multiplicative constant, the same as
classical precision ($1/\sigma^2$).&lt;/p&gt;
&lt;p&gt;This measure has a number of properties that you might expect for
something called a precision&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;For any non-trivial experiment, $\beta&amp;gt;0$&lt;/li&gt;
&lt;li&gt;$n$ samples from the same experiment has precision $n\beta$&lt;/li&gt;
&lt;li&gt;Blackwell dominant experiments have higher precision&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Intuitively, you can think of the Chernoff precision as measuring how
well an information source can distinguish between a given pair of
states.&lt;/p&gt;
&lt;p&gt;Because the Chernoff number of a composite is weakly higher than the
product of the individual Chernoff numbers, a composite experiment is
weakly less precise, for a given state, than the sum of it&amp;rsquo;s parts.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# the following returns the full list of state-pair precisions&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# and their respective MGF minimizers&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;precisions&lt;/span&gt;(Q):
    numstates &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Q&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
    &lt;span style=&#34;color:#75715e&#34;&gt;# compute the Chernoff index for each state&lt;/span&gt;
    betalist &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    taulist &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; state1 &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(numstates):
        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; state2 &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(state1&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, numstates):
            &lt;span style=&#34;color:#75715e&#34;&gt;# Define the llr mgf for the given dichtomy&lt;/span&gt;
            &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;llrmgf&lt;/span&gt;(t):
                Qstate1t &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Q[state1, :]&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;t
                Qstate2t &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Q[state2, :]&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;t)
                &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum(Qstate1t &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; Qstate2t)
            &lt;span style=&#34;color:#75715e&#34;&gt;# Compute index for the dichotomy&lt;/span&gt;
            optimizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; optim&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;minimize(llrmgf, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;)
            rho &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; optimizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fun
            tau &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; optimizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;x[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
            betalist&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log(rho))
            taulist&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(tau)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; betalist, taulist


beta1list, tau1list &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; precisions(Q1)
beta2list, tau2list &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; precisions(Q2)
beta12list, tau12list &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; precisions(composite_source(Q1, Q2))
table &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([beta12list, [beta1list[i]&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;beta2list[i]
                               &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(len(beta1list))]])&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;T
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(tabulate(table,
               headers&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;composite precisions&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sum of parts&amp;#34;&lt;/span&gt;]))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;  composite precisions    sum of parts
----------------------  --------------
              0.149026        0.149196
              0.271436        0.276094
              0.343391        0.343559
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, it might seem that composites are always worse than the sum of
their parts since, for any state pair, the composite is always less
precise than the sum of its parts. But Moscarini and Smith (2002) showed
that, for large sample sizes, the only state pair that matters is the
pair hardest to tell apart&amp;mdash;i.e. the pair with the least precision
(highest Chernoff index).&lt;/p&gt;
&lt;p&gt;Thus complementarity often arises when experiments differ in the pair of
states they most struggle to distinguish:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;beta1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; min(beta1list)
beta2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; min(beta2list)
beta12 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; min(beta12list)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(tabulate([[beta12, beta1&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;beta2]],
               headers&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;min precision of composite&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sum of min precisions&amp;#34;&lt;/span&gt;]))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;  min precision of composite    sum of min precisions
----------------------------  -----------------------
                    0.149026                 0.051485
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this particular example, we can see that it is in fact the composite
has a &lt;em&gt;higher&lt;/em&gt; least precision than the sum of least precisions of its
parts.&lt;/p&gt;
&lt;h1 id=&#34;plotting-indifference-curves&#34;&gt;Plotting &amp;ldquo;indifference curves&amp;rdquo;&lt;/h1&gt;
&lt;p&gt;In particular, at large samples, two bundles of samples will perform
equally if they have equal least precision. Information value at large
samples is ordinally equivalent to&lt;/p&gt;
&lt;p&gt;$$
v(n_1, n_2) \simeq (n_1+n_2)\beta_\omega
$$&lt;/p&gt;
&lt;p&gt;where $\beta_\omega$ is the least precision dichotomy for a bundle that
is composed of $\omega$ fraction of samples from $n_1$. Furthermore, we
can breakdown $\beta_\omega$ into component precisions:&lt;/p&gt;
&lt;p&gt;$$
\beta_\omega=\omega\beta_{\omega 1}+(1-\omega)\beta_{\omega 2}
$$&lt;/p&gt;
&lt;p&gt;where $\beta_{\omega i}$ is $-\log M_i(\tau_\omega)$, is the negative
log of the LLR MGF for the composite&amp;rsquo;s worst-case state pair, evaluated
at the composite&amp;rsquo;s minimizer. We can then write&lt;/p&gt;
&lt;p&gt;$$
v(n_1, n_2) \simeq n_1\beta_{\omega 1} + n_2\beta_{\omega 2}
$$&lt;/p&gt;
&lt;p&gt;Heuristically, then it seems like the MRS between two samples at any
bundle with $\omega$ fraction from $\mathcal{E}_1$ must then be the
ratio of the component precisions. (For small substitutions, relative
to total sample size, the fraction of samples from each source doesn&amp;rsquo;t
change much, so the component precisions don&amp;rsquo;t change much.)&lt;/p&gt;
&lt;p&gt;Additionally, since the value is a min of a sums of precisions, there
will be kinks when the least-precision state pair changes.&lt;/p&gt;
&lt;p&gt;Of course, samples are fundamentally discrete so there is no MRS. In the
paper, I formally define a notion of asymptotic MRS, which basically
defines the slope of the boundary between upper and lower contour
sets. For the purpose of interpreting things here, it works well enough
to just pretend samples are divisible.&lt;/p&gt;
&lt;p&gt;First, note that the component precisions only depend on the fraction of
the bundle from each source (info value is homothetic). First, I compute
the component precision for a given composite factor $\omega$.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;n1start &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# return the component precision for each test at the w composite factor&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;comp_precision&lt;/span&gt;(Q1, Q2, w):
    numstates &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Q1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
    &lt;span style=&#34;color:#75715e&#34;&gt;# loop over pairs of states&lt;/span&gt;
    rho &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; state1 &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(numstates):
        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; state2 &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(state1&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, numstates):
            &lt;span style=&#34;color:#75715e&#34;&gt;# Define the Hellinger transform for the given dichtomy&lt;/span&gt;
            &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;llrmgf1&lt;/span&gt;(t):
                Q1state1_t &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Q1[state1, :]&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;t
                Q1state2_t &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Q1[state2, :]&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;t)
                &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum(Q1state1_t&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;Q1state2_t)

            &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;llrmgf2&lt;/span&gt;(t):
                Q2state1_t &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Q2[state1, :]&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;t
                Q2state2_t &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Q2[state2, :]&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;t)
                &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum(Q2state1_t&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;Q2state2_t)

            &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;compllrmgf&lt;/span&gt;(t):
                &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; llrmgf1(t)&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;w &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; llrmgf2(t)&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;w)

            &lt;span style=&#34;color:#75715e&#34;&gt;# Compute Chernoff for the dichotomy&lt;/span&gt;
            optimizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; optim&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;minimize(compllrmgf, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;)
            rhopair &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; optimizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fun
            taupair &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; optimizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;x
            &lt;span style=&#34;color:#75715e&#34;&gt;# if new rho is worse (higher), store it&lt;/span&gt;
            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; rho &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; rhopair:
                rho &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; rhopair
                &lt;span style=&#34;color:#75715e&#34;&gt;# Store component rhos&lt;/span&gt;
                rho1w &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; llrmgf1(taupair)
                rho2w &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; llrmgf2(taupair)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log(rho1w), &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log(rho2w)

&lt;span style=&#34;color:#75715e&#34;&gt;# return total precision for a composite factor w&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;total_precision&lt;/span&gt;(Q1, Q2, w):
    beta1w, beta2w &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; comp_precision(Q1, Q2, w)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; w&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;beta1w &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;w)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;beta2w
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can then compute points on an indifference curve by using the
differential equation defined by the asymptotic MRS ($dn_2/dn_1$):&lt;/p&gt;
&lt;p&gt;$$
\text{AMRS}(\omega) = \frac{\beta_{\omega 1}}{\beta_{\omega 2}}
$$&lt;/p&gt;
&lt;p&gt;In all the plots that follow, the reference point is the lower right
corner bundle consisting entirely of samples from $\mathcal{E}_1$.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mrs_approx&lt;/span&gt;(n1start):
    dn &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.01&lt;/span&gt;
    n1pointsapprox &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(n1start, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;dn, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;dn)
    n2pointsapprox &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    n2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; n1 &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; n1pointsapprox:
        w &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; n1 &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; (n1 &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; n2)
        beta1w, beta2w &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; comp_precision(Q1, Q2, w)
        n2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; n2 &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; dn&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;(beta1w&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;beta2w)
        n2pointsapprox&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(n2)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; n1pointsapprox, n2pointsapprox


n1pointsapprox, n2pointsapprox &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mrs_approx(n1start)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now we can compare this to the true upper/lower contour set computed
numerically using the info value function defined earlier. The plot
below shows the locus of bundles that are minimally better than the
reference point (the maximal boundary for the upper contour set).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mrs_true&lt;/span&gt;(n1start):
    Q1n &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; n_samples(Q1, n1start)
    startval &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; info_value(Q1n, U, P)
    &lt;span style=&#34;color:#75715e&#34;&gt;# Trace out the lower extent of the UCS&lt;/span&gt;
    n2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;      &lt;span style=&#34;color:#75715e&#34;&gt;# start with no samples from Q2&lt;/span&gt;
    n1pointstrue &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(n1start, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    n2pointstrue &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; n1loss &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, n1start&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
        Q1n &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; n_samples(Q1, n1start&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;n1loss)
        &lt;span style=&#34;color:#75715e&#34;&gt;# find minimum samples from Q2 to make better off&lt;/span&gt;
        currentval &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; currentval &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; startval:
            n2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; n2 &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
            Q2n &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; n_samples(Q2, n2)
            Qcomp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; composite_source(Q1n, Q2n)
            currentval &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; info_value(Qcomp, U, P)
        n2pointstrue&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(n2)
        n2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; n2 &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;     &lt;span style=&#34;color:#75715e&#34;&gt;# decr. n2 just to be sure later&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; n1pointstrue, n2pointstrue


n1pointstrue, n2pointstrue &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mrs_true(n1start)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;fig &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;), dpi&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;)
ax &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; fig&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_xlim((&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, n1start))
ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_ylim((&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, max(n2pointstrue)))
ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Number of samples from Experiment 1&amp;#39;&lt;/span&gt;)
ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Number of samples from Experiment 2&amp;#39;&lt;/span&gt;)
ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(n1pointstrue, n2pointstrue, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;k&amp;#39;&lt;/span&gt;,
        n1pointsapprox, n2pointsapprox, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;--k&amp;#39;&lt;/span&gt;);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;./info-consumer-theory_37_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Now compute the relative info gap for the indifference curve plotted
above. Higher relative info-gap implies the approximation is useful even
at small samples.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;Q1n &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; n_samples(Q1, n1start)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(tabulate([[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Relative info-gap:&amp;#34;&lt;/span&gt;,
                 relative_info_gap(Q1n, U, P)]]))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;------------------  ---------
Relative info-gap:  0.0438343
------------------  ---------
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that the approximation effectively sets the probability of a
mistake other than the most likely one to zero. This approximation then
tends to &lt;em&gt;overestimate&lt;/em&gt; payoffs, and thus the approximate MRS will tend
to lie to left of the truth.&lt;/p&gt;
&lt;p&gt;In the above plot, we can see that approximation performs relatively
well, even at small sample sizes. One limitation is that the
approximation will always perform somewhat poorly in a region around a
kink for two reasons:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The second lowest precision is very close to the lowest, so only
accounting for the lowest precision doesn&amp;rsquo;t work as well; and,&lt;/li&gt;
&lt;li&gt;Because the kinks are inward pointing, total sample size tends to be
lower there. In the above example, the corners have total sample size
between 40 and 50, but the kink has only about 15 total samples.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;But regardless, as sample size increases, we can always get an
arbitrarily good approximation for composite factors arbitrarily close
to that of any kink point.&lt;/p&gt;
&lt;p&gt;Below I plot again, but at twice the sample size to illustrate the
convergence:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;n1start &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;
n1pointsapprox, n2pointsapprox &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mrs_approx(n1start)
n1pointstrue, n2pointstrue &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mrs_true(n1start)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;fig &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;), dpi&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;500&lt;/span&gt;)
ax &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; fig&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_xlim((&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, n1start))
ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_ylim((&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, max(n2pointstrue)))
ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Number of samples from Experiment 1&amp;#39;&lt;/span&gt;)
ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Number of samples from Experiment 2&amp;#39;&lt;/span&gt;)
ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(n1pointstrue, n2pointstrue, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;k&amp;#39;&lt;/span&gt;,
        n1pointsapprox, n2pointsapprox, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;--k&amp;#39;&lt;/span&gt;);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;./info-consumer-theory_43_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;Q1n &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; n_samples(Q1, n1start)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(tabulate([[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Relative info-gap:&amp;#34;&lt;/span&gt;,
                 relative_info_gap(Q1n, U, P)]]))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;------------------  --------
Relative info-gap:  0.011011
------------------  --------
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Past Course Materials</title>
      <link>https://www.garygbaker.com/teaching/past/</link>
      <pubDate>Tue, 29 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://www.garygbaker.com/teaching/past/</guid>
      <description>
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.garygbaker.com/teaching/s2018econ101/&#34;&gt;Spring 2018 - Economics 101 - Principles of Microeconomics&lt;/a&gt; (Head TA)&lt;br&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.garygbaker.com/teaching/f2017econ101/&#34;&gt;Fall 2017 - Economics 101 - Principles of Microeconomics&lt;/a&gt; (Head TA)&lt;br&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://sites.google.com/site/garygbaker/fall-2015---econ-102&#34;&gt;Fall 2015 - Economics 102 - Principles of Macroeconomics &lt;/a&gt; (Head TA) &lt;br&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://sites.google.com/site/garygbaker/spring-2015---econ-101&#34;&gt;Spring 2015 - Economics 101 - Principles of Microeconomics &lt;/a&gt;&lt;br&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://sites.google.com/site/garygbaker/fall-2014---econ-101&#34;&gt;Fall 2014 - Economics 101 - Principles of Macroeconomics &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


</description>
    </item>
    
    <item>
      <title>Economics 101</title>
      <link>https://www.garygbaker.com/teaching/s2018econ101/</link>
      <pubDate>Fri, 04 May 2018 00:00:00 +0000</pubDate>
      <guid>https://www.garygbaker.com/teaching/s2018econ101/</guid>
      <description>&lt;div class=&#34;row&#34;&gt;
&lt;style type=&#34;text/css&#34;&gt;
 #sidebar {
     background: #cccccc;
     font-family: monospace
 }
&lt;/style&gt;
&lt;div class=&#34;col-xs-12 col-md-5&#34; id=&#34;sidebar&#34;&gt;
    &lt;p&gt;&lt;strong&gt;Professor:&lt;/strong&gt; Elizabeth Kelly&lt;br&gt;
&lt;strong&gt;Lecture:&lt;/strong&gt; TuesThurs 1:00 - 2:15 PM&lt;br&gt;
&lt;a href=&#34;http://www.ssc.wisc.edu/~ekelly/econ101/&#34;&gt;Course Page&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TA:&lt;/strong&gt; Gary Baker&lt;br&gt;
&lt;strong&gt;Office:&lt;/strong&gt; Soc Sci 6470&lt;br&gt;
&lt;strong&gt;Office Hours:&lt;/strong&gt; Mon 11AM-12PM, Wed 2-3PM, or by appointment&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Discussion Sections&lt;/strong&gt;&lt;br&gt;
(315)Thu 3:30-4:20PM - Sterling 2319&lt;br&gt;
(303)Fri 1:20-2:10PM - Van Hise 386&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exams&lt;/strong&gt;&lt;br&gt;
Midterm 1 - Tues, 27 Feb (in class)&lt;br&gt;
Midterm 2 - Tues, 10 Apr (in class)&lt;br&gt;
Final - Sun, 6 May (7:45 - 9:45 AM)&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Homework&lt;/strong&gt;&lt;br&gt;
Homework 1 (Due Thurs,  8 Feb)&lt;br&gt;
Homework 2 (Due Thurs, 22 Feb)&lt;br&gt;
Homework 3 (Due Thurs, 15 Mar)&lt;br&gt;
Homework 4 (Due Thurs, 5 Apr)&lt;br&gt;
Homework 5 (Due Thurs, 3 May)&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Discussion Handouts&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://www.dropbox.com/s/qbemvf2igxmb01u/handout1.pdf?dl=0&#34;&gt;Handout 1&lt;/a&gt; (&lt;a href=&#34;https://www.dropbox.com/s/mcp4b9jlt4qmn9c/handout1Solutions.pdf?dl=0&#34;&gt;Solutions&lt;/a&gt;)&lt;br&gt;
&lt;a href=&#34;https://www.dropbox.com/s/bxv8c7mekxu4tia/handout2.pdf?dl=0&#34;&gt;Handout 2&lt;/a&gt; (&lt;a href=&#34;https://www.dropbox.com/s/fhlmje1at46ht77/handout2-solutions.pdf?dl=0&#34;&gt;Solutions&lt;/a&gt;)&lt;br&gt;
&lt;a href=&#34;https://www.dropbox.com/s/b98fk6bmp93jeuh/handout3.pdf?dl=0&#34;&gt;Handout 3&lt;/a&gt; (&lt;a href=&#34;https://www.dropbox.com/s/vlm7u74bpu8hh4b/handout3-solutions.pdf?dl=0&#34;&gt;Solutions&lt;/a&gt;)&lt;br&gt;
&lt;a href=&#34;https://www.dropbox.com/s/bvmht9jt99070g3/handout4.pdf?dl=0&#34;&gt;Handout 4&lt;/a&gt; (&lt;a href=&#34;https://www.dropbox.com/s/eeumha1fg5waifh/handout4-solutions.pdf?dl=0&#34;&gt;Solutions&lt;/a&gt;)&lt;br&gt;
&lt;a href=&#34;https://www.dropbox.com/s/ce866baq233pua5/handout5.pdf?dl=0&#34;&gt;Handout 5&lt;/a&gt; (&lt;a href=&#34;https://www.dropbox.com/s/y1ttydsp59avm6w/handout5-solutions.pdf?dl=0&#34;&gt;Solutions&lt;/a&gt;)&lt;br&gt;
&lt;a href=&#34;https://www.dropbox.com/s/085ie5vm3jioh91/handout6.pdf?dl=0&#34;&gt;Handout 6&lt;/a&gt; (&lt;a href=&#34;https://www.dropbox.com/s/101b425tb9vv3ft/handout6-solutions.pdf?dl=0&#34;&gt;Solutions&lt;/a&gt;)&lt;br&gt;
&lt;a href=&#34;https://www.dropbox.com/s/wn6w7nsrexd9su2/handout7.pdf?dl=0&#34;&gt;Handout 7&lt;/a&gt; (&lt;a href=&#34;https://www.dropbox.com/s/ev0i1dmklqhd7mx/handout7-solutions.pdf?dl=0&#34;&gt;Solutions&lt;/a&gt;)&lt;br&gt;
&lt;a href=&#34;https://www.dropbox.com/s/wpjnbz9ug2kg2lm/handout8.pdf?dl=0&#34;&gt;Handout 8&lt;/a&gt; (&lt;a href=&#34;https://www.dropbox.com/s/xfnadmtz7ohsj10/handout8-solutions.pdf?dl=0&#34;&gt;Solutions&lt;/a&gt;)&lt;br&gt;
&lt;a href=&#34;https://www.dropbox.com/s/qk1iinglwqshuk5/handout9.pdf?dl=0&#34;&gt;Handout 9&lt;/a&gt; (&lt;a href=&#34;https://www.dropbox.com/s/az93w7zkha0m157/handout9-solutions.pdf?dl=0&#34;&gt;Solutions&lt;/a&gt;)&lt;br&gt;
&lt;a href=&#34;https://www.dropbox.com/s/x4cmycn3edbqfbd/handout10.pdf?dl=0&#34;&gt;Handout 10&lt;/a&gt; (&lt;a href=&#34;https://www.dropbox.com/s/0tf577a5lfhz8mi/handout10-solutions.pdf?dl=0&#34;&gt;Solutions&lt;/a&gt;)&lt;br&gt;
&lt;a href=&#34;https://www.dropbox.com/s/46ri40q0wlb8mnf/handout11.pdf?dl=0&#34;&gt;Handout 11&lt;/a&gt; (&lt;a href=&#34;https://www.dropbox.com/s/5ayo5zzfle7qb47/handout11-solutions.pdf?dl=0&#34;&gt;Solutions&lt;/a&gt;)&lt;br&gt;
&lt;a href=&#34;https://www.dropbox.com/s/r42hqcywjzrvvug/handout12.pdf?dl=0&#34;&gt;Handout 12&lt;/a&gt; (&lt;a href=&#34;https://www.dropbox.com/s/8sfdcgxwjbq0zz7/handout12-solutions.pdf?dl=0&#34;&gt;Solutions&lt;/a&gt;)&lt;br&gt;
&lt;a href=&#34;https://www.dropbox.com/s/nss302hus4twjt2/handout13.pdf?dl=0&#34;&gt;Handout 13&lt;/a&gt; (&lt;a href=&#34;https://www.dropbox.com/s/4de81i7i5fdpznj/handout13-solutions.pdf?dl=0&#34;&gt;Solutions&lt;/a&gt;)&lt;br&gt;
&lt;a href=&#34;https://www.dropbox.com/s/oupwpb9r3i38zco/handout14.pdf?dl=0&#34;&gt;Handout 14&lt;/a&gt; (&lt;a href=&#34;https://www.dropbox.com/s/27kad8n28fdnwy4/handout14-solutions.pdf?dl=0&#34;&gt;Solutions&lt;/a&gt;)&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;col-xs-12 col-md-7&#34;&gt;
    &lt;p&gt;Welcome to my Econ 101 page for Spring 2018. Here I will post various updates throughout the semester for my students, as well as provide links to the weekly handouts as they become available. More detailed information on the course can be found on Professor Kelly&amp;rsquo;s &lt;a href=&#34;http://www.ssc.wisc.edu/~ekelly/econ101/&#34;&gt;webpage&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Updates&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;28 January&lt;/em&gt; - I&amp;rsquo;ve uploaded Handout 1 and its solutions. If some of the topics covered in section this week seem a bit unclear, feel free to email me or attend office hours, but also to solve some of the exercises not covered on the handout. Mathematical fluency will come with practice.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;4 February&lt;/em&gt; - Handout 2 has been uploaded. Don&amp;rsquo;t forget that the first homework is due this Thursday at the start of lecture.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;18 February&lt;/em&gt; - Handouts 3 and 4 uploaded. HW 2 is due this coming Thursday at the start of class, and the first midterm is one week from this Tuesday. More details will be sent via email later this week.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;21 March&lt;/em&gt; - Apologies for the delay in updates on account of my recent illness. I&amp;rsquo;ve updated the handouts up to Handout 8.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;24 April&lt;/em&gt; - Handouts updated through handout 12. Homework 5 is due Thursday, 3 May. We will not be able to return it before the final exam, so make sure you make a copy if you want it to study by.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;4 May&lt;/em&gt; - Final handouts added. Good luck on the exam and have a good break!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Economics 101</title>
      <link>https://www.garygbaker.com/teaching/f2017econ101/</link>
      <pubDate>Tue, 12 Dec 2017 00:00:00 +0000</pubDate>
      <guid>https://www.garygbaker.com/teaching/f2017econ101/</guid>
      <description>&lt;div class=&#34;row&#34;&gt;
&lt;style type=&#34;text/css&#34;&gt;
 #sidebar {
     background: #cccccc;
     font-family: monospace
 }
&lt;/style&gt;
&lt;div class=&#34;col-xs-12 col-md-5&#34; id=&#34;sidebar&#34;&gt;
    &lt;p&gt;&lt;strong&gt;Professor:&lt;/strong&gt; Elizabeth Kelly&lt;br&gt;
&lt;strong&gt;Lecture:&lt;/strong&gt; TuesThurs 8:30-9:40AM&lt;br&gt;
&lt;a href=&#34;http://www.ssc.wisc.edu/~ekelly/econ101/&#34;&gt;Course Page&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TA:&lt;/strong&gt; Gary Baker&lt;br&gt;
&lt;strong&gt;Office:&lt;/strong&gt; Soc Sci 6470&lt;br&gt;
&lt;strong&gt;Office Hours:&lt;/strong&gt; Mon/Fri 11AM-12PM, or by appointment&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Discussion Sections&lt;/strong&gt;&lt;br&gt;
(315)Thu 3:30-4:20PM - Sterling 2319&lt;br&gt;
(303)Fri 1:20-2:10PM - Van Hise 386&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exams&lt;/strong&gt;&lt;br&gt;
Midterm 1 - Thurs, 12 Oct (in class)&lt;br&gt;
Midterm 2 - Thurs, 16 Nov (in class)&lt;br&gt;
Final - Tues, 19 Dec (12:25-2:25 PM)&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Homework&lt;/strong&gt;&lt;br&gt;
Homework 1 (Due Tues,  3 Oct)&lt;br&gt;
Homework 2 (Due Tues, 10 Oct)&lt;br&gt;
Homework 3 (Due Tues, 31 Oct)&lt;br&gt;
Homework 4 (Due Tues, 14 Nov)&lt;br&gt;
Homework 5 (Due Tues, 12 Dec)&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Discussion Handouts&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;https://drive.google.com/open?id=0B0B9_804AJMoNnJ0YXEyMjR4Z2s&#34;&gt;Handout 1&lt;/a&gt; (&lt;a href=&#34;https://drive.google.com/open?id=0B0B9_804AJMoUTlVSUFmd3V0bFE&#34;&gt;Solutions&lt;/a&gt;)&lt;br&gt;
&lt;a href=&#34;https://drive.google.com/open?id=0B0B9_804AJMobWt3dXZhZDA1YnM&#34;&gt;Handout 2&lt;/a&gt; (&lt;a href=&#34;https://drive.google.com/open?id=0B0B9_804AJMoaU5MSURDUzFJTGs&#34;&gt;Solutions&lt;/a&gt;)&lt;br&gt;
&lt;a href=&#34;https://drive.google.com/open?id=0B0B9_804AJMoakpFaEM4ZThfd3M&#34;&gt;Handout 3&lt;/a&gt; (&lt;a href=&#34;https://drive.google.com/open?id=0B0B9_804AJMoWEtuaHhIT3QzMG8&#34;&gt;Solutions&lt;/a&gt;)&lt;br&gt;
&lt;a href=&#34;https://www.dropbox.com/s/kdh7ml5w2ms0eik/handout4.pdf?dl=0&#34;&gt;Handout 4&lt;/a&gt; (&lt;a href=&#34;https://www.dropbox.com/s/fgfxjc98y7d4xhk/handout4-solutions.pdf?dl=0&#34;&gt;Solutions&lt;/a&gt;)&lt;br&gt;
&lt;a href=&#34;https://www.dropbox.com/s/u3cjgxchbmbj85w/handout5.pdf?dl=0&#34;&gt;Handout 5&lt;/a&gt; (&lt;a href=&#34;https://www.dropbox.com/s/p4dnlxqgqnirib1/handout5-solutions.pdf?dl=0&#34;&gt;Solutions&lt;/a&gt;)&lt;br&gt;
&lt;a href=&#34;https://www.dropbox.com/s/9mghegqj9byrs92/handout6.pdf?dl=0&#34;&gt;Handout 6&lt;/a&gt; (&lt;a href=&#34;https://www.dropbox.com/s/g0o9sdrurqokfja/Handout6-Solutions.pdf?dl=0&#34;&gt;Solutions&lt;/a&gt;)&lt;br&gt;
&lt;a href=&#34;https://www.dropbox.com/s/z72hv4fuexuvhhn/handout7.pdf?dl=0&#34;&gt;Handout 7&lt;/a&gt; (&lt;a href=&#34;https://www.dropbox.com/s/ezjl9eyz3zhu018/Handout7-Solutions.pdf?dl=0&#34;&gt;Solutions&lt;/a&gt;)&lt;br&gt;
&lt;a href=&#34;https://www.dropbox.com/s/zawfm8qwx6x1y50/handout8.pdf?dl=0&#34;&gt;Handout 8&lt;/a&gt; (&lt;a href=&#34;https://www.dropbox.com/s/sf7bixcukco2rhc/handout8-solutions.pdf?dl=0&#34;&gt;Solutions&lt;/a&gt;)&lt;br&gt;
&lt;a href=&#34;https://www.dropbox.com/s/gqh1wgwki2ssv04/handout9.pdf?dl=0&#34;&gt;Handout 9&lt;/a&gt;  (&lt;a href=&#34;https://www.dropbox.com/s/ack3wotxmcvobt2/handout9-solutions.pdf?dl=0&#34;&gt;Solutions&lt;/a&gt;)&lt;br&gt;
&lt;a href=&#34;https://www.dropbox.com/s/42q9djj34ot905n/handout10.pdf?dl=0&#34;&gt;Handout 10&lt;/a&gt; (&lt;a href=&#34;https://www.dropbox.com/s/zktwo2qkn3eiuwy/handout10-solutions.pdf?dl=0&#34;&gt;Solutions&lt;/a&gt;)&lt;br&gt;
&lt;a href=&#34;https://www.dropbox.com/s/fxmv1c06zqk3xcc/handout11.pdf?dl=0&#34;&gt;Handout 11&lt;/a&gt; (&lt;a href=&#34;https://www.dropbox.com/s/47zzzkhjrwvn14n/handout11-solutions.pdf?dl=0&#34;&gt;Solutions&lt;/a&gt;)&lt;br&gt;
&lt;a href=&#34;https://www.dropbox.com/s/ptxgreyd68pt63c/handout12.pdf?dl=0&#34;&gt;Handout 12&lt;/a&gt; (&lt;a href=&#34;https://www.dropbox.com/s/z46q46pg724wtps/handout12-solutions.pdf?dl=0&#34;&gt;Solutions&lt;/a&gt;)&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;col-xs-12 col-md-7&#34;&gt;
    &lt;p&gt;Welcome to my Econ 101 page for Fall 2017. Here I will post various updates throughout the semester for my students, as well as provide links to the weekly handouts as they become available. More detailed information on the course can be found on Professor Kelly&amp;rsquo;s &lt;a href=&#34;http://www.ssc.wisc.edu/~ekelly/econ101/&#34;&gt;webpage&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Updates&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;12 December&lt;/em&gt; - Handout 12 posted. Good luck on the final exam, and have a good break!&lt;/p&gt;
&lt;p&gt;&lt;em&gt;5 December&lt;/em&gt; - Handout 11 posted.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;19 November&lt;/em&gt; - Handouts 9 and 10 posted. Exam grades should be posted to Canvas some time this week. Have a good Thanksgiving break!&lt;/p&gt;
&lt;p&gt;&lt;em&gt;6 November&lt;/em&gt; - Handout 8 posted. HW 3 has been graded and can be collected from me during office hours or section.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;30 October&lt;/em&gt; - Handout 7 posted. HW 3 due tomorrow. As a reminder, some of the harder topics of the course are coming up, so make use of the resources available to you in order not to fall behind.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;25 October&lt;/em&gt; - Handout 6 uploaded.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;8 October&lt;/em&gt; - Handout 5 uploaded. The first homework has been graded and can be picked up during my office hours on Monday (11 AM - 12 PM and 2 - 3 PM). Don&amp;rsquo;t forget that HW 2 is due Tuesday at the start of lecture, and that if you want to use it to study, to make a copy of it, since we won&amp;rsquo;t be able to return it before the exam.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;1 October&lt;/em&gt; - Handout 4 uploaded. The first Midterm will be on Thursday, 12 October. If you are looking to get a headstart on studying, the first place to look should be the past exams on Professor Kelly&amp;rsquo;s &lt;a href=&#34;http://www.ssc.wisc.edu/~ekelly/econ101/&#34;&gt;webpage&lt;/a&gt;, particularly those from past fall and spring semesters.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;25 September&lt;/em&gt; - Handout 3 uploaded. As a reminder the homework due date has been pushed to Tuesday, 3 October to allow you more time with the PPF material.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;20 September&lt;/em&gt; - Handout 2 has been uploaded. Last section was a lot to take in given that we were a bit ahead of the lecture. Although we will be following the lecture from here on, the pace will not slow down, so it is important to keep up. If anything is confusing, you should work practice problems and ask questions in office hours until you achieve clarity on the topic. Many ideas will build on earlier ones, so unresolved confusion will compound.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;10 September&lt;/em&gt; - I&amp;rsquo;ve uploaded Handout 1 and its solutions. If some of the topics covered in section this week seem a bit unclear, feel free to email me or attend office hours, but also to solve some of the exercises not covered on the handout. Mathematical fluency will come with practice.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Colophon</title>
      <link>https://www.garygbaker.com/colophon/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://www.garygbaker.com/colophon/</guid>
      <description>&lt;p&gt;This site was produced using the &lt;a href=&#34;http://gohugo.io&#34;&gt;Hugo&lt;/a&gt; static site generator with the &lt;a href=&#34;https://github.com/gcushen/hugo-academic&#34;&gt;Academic&lt;/a&gt; theme by &lt;a href=&#34;https://georgecushen.com/&#34;&gt;George Cushen&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Text and headings are set in &lt;a href=&#34;https://huertatipografica.com/en&#34;&gt;Huerta TipogrÃ¡fica&lt;/a&gt; Alegreya and Alegreya Sans respectively. Code is set in &lt;a href=&#34;https://www.colophon-foundry.org/&#34;&gt;Colophon&lt;/a&gt; Space Mono. All typefaces are provided by &lt;a href=&#34;https://fonts.google.com/&#34;&gt;Google Fonts&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Hosting is provided by &lt;a href=&#34;https://pages.github.com&#34;&gt;Github Pages&lt;/a&gt;.
&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;image-attribution&#34;&gt;Image Attribution&lt;/h2&gt;
&lt;div class=&#34;row&#34;&gt;

&lt;p&gt;&lt;a href=&#34;https://what-if.xkcd.com/111/&#34;&gt;&lt;img style=&#34;margin:15px;&#34; align=&#34;left&#34; src=&#34;https://www.garygbaker.com/img/summon.png&#34;/&gt;&lt;/a&gt; Copyright Â© Randall Munroe. Used according to a &lt;a href=&#34;https://creativecommons.org/licenses/by-nc/2.5/&#34;&gt;CC BY-NC 2.5&lt;/a&gt; License.&lt;/p&gt;
&lt;/div&gt;

</description>
    </item>
    
  </channel>
</rss>
